import argparse
import datetime
import json
import logging
import math
import os
import random
import time
from copy import deepcopy

import numpy as np
import scipy.io as sio
import matplotlib
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda import amp

from sklearn import preprocessing
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score
from sklearn.decomposition import PCA
from skimage.segmentation import slic

from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import add_self_loops, get_laplacian, dense_to_sparse

# ==============================================================================
# Mamba Imports
# ==============================================================================
try:
    from mamba_ssm import Mamba
except ImportError:
    from mamba_ssm.modules.mamba_simple import Mamba

try:
    from mamba_ssm.ops.triton.layernorm import RMSNorm
except Exception:
    RMSNorm = nn.LayerNorm

# ==============================================================================
# Logger & Utils
# ==============================================================================
def seed_everything(seed=3407):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def setup_logger(output_dir: str):
    os.makedirs(os.path.join(output_dir, "log"), exist_ok=True)
    run_id = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = os.path.join(output_dir, "log", f"log_run_{run_id}.txt")
    logger = logging.getLogger(f"GCNAS-Final-{run_id}")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    def beijing(sec, what):
        return datetime.datetime.now().timetuple()
    
    logging.Formatter.converter = beijing
    formatter = logging.Formatter("%(asctime)s: %(message)s", "%Y-%m-%d %H:%M:%S")
    
    fh = logging.FileHandler(log_path)
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    
    ch = logging.StreamHandler()
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    return logger, run_id

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

class TimeTracker:
    def __init__(self):
        self.phases = {}
    def start(self, phase):
        self.phases[phase] = {"start": time.time(), "end": None}
    def stop(self, phase):
        if phase in self.phases:
            self.phases[phase]["end"] = time.time()
    def get_duration(self, phase):
        if phase in self.phases and self.phases[phase]["end"]:
            return self.phases[phase]["end"] - self.phases[phase]["start"]
        return 0.0

class EarlyStopping:
    def __init__(self, patience=20, min_delta=0.0, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_epoch = 0
    
    def __call__(self, score, epoch):
        if self.best_score is None: 
            self.best_score = score
            self.best_epoch = epoch
            return True
        
        if self.mode == 'max':
            improved = score > self.best_score + self.min_delta
        else:
            improved = score < self.best_score - self.min_delta
        
        if improved:
            self.best_score = score
            self.best_epoch = epoch
            self.counter = 0
            return True
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
            return False

def save_config(args, output_dir, run_id, num_params, additional_info=None):
    config = vars(args).copy()
    config['num_params'] = num_params
    config['num_params_M'] = num_params / 1e6
    config['run_id'] = run_id
    if additional_info:
        config.update(additional_info)
    config_path = os.path.join(output_dir, f'config_{run_id}.json')
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    return config_path

# ==============================================================================
# Data Utils
# ==============================================================================
def SegmentsLabelProcess(line, sample, labels):
    labels = np.array(labels, np.int64)
    ls = list(set(np.reshape(labels, [-1]).tolist()))
    dic = {ls[i]: i for i in range(len(ls))}
    new_labels = labels.copy()
    for i in range(line):
        for j in range(sample):
            new_labels[i, j] = dic[new_labels[i, j]]
    return new_labels

class SegmentMap(object):
    def __init__(self, data_in, Unet_depth=3, random_seed=3407):
        self.line, self.sample, self.band = data_in.shape
        data = np.reshape(data_in, [self.line * self.sample, self.band])
        self.data = np.reshape(
            preprocessing.StandardScaler().fit_transform(data),
            [self.line, self.sample, self.band]
        )
        self.Unet_depth = Unet_depth
        self.random_seed = random_seed

    def getHierarchy(self):
        np.random.seed(self.random_seed)
        h, w = self.line, self.sample
        n_s = 256
        n_segments = []
        for _ in range(self.Unet_depth):
            n_segments.append(n_s)
            n_s = n_s * 2

        segs = []
        for i in range(self.Unet_depth):
            segment = slic(
                self.data,
                n_segments=n_segments[-i - 1],
                compactness=1, 
                max_num_iter=20,
                sigma=1,
                convert2lab=False,
                enforce_connectivity=False,
                start_label=1,
                min_size_factor=0.1,
                max_size_factor=2,
                slic_zero=False
            )
            if segment.max() + 1 != len(np.unique(segment)):
                segment = SegmentsLabelProcess(h, w, segment)
            segs.append(segment)

        A_list = []
        for l in range(len(segs)):
            map_ = np.reshape(segs[l], [h, w])
            count = int(np.max(segs[l])) + 1
            A = torch.zeros([count, count], dtype=torch.int16)
            right = np.vstack([map_[:, :-1].ravel(), map_[:, 1:].ravel()]).T
            down = np.vstack([map_[:-1, :].ravel(), map_[1:, :].ravel()]).T
            edges = np.vstack([
                right[right[:, 0] != right[:, 1]],
                down[down[:, 0] != down[:, 1]]
            ])
            if len(edges) > 0:
                for u, v in edges:
                    A[u, v] = A[v, u] = 1
            A_list.append(A)

        segs = np.concatenate([
            np.reshape([i for i in range(h * w)], [1, h, w]),
            segs
        ], axis=0)
        
        H_list_full = []
        
        S = np.zeros([np.max(segs[0]) + 1, np.max(segs[1]) + 1], dtype=np.float32)
        l1, l2 = np.reshape(segs[0], [-1]), np.reshape(segs[1], [-1])
        coords = np.stack([l1, l2])
        coords = np.unique(coords, axis=1)
        S[coords[0], coords[1]] = 1
        H_list_full.append(S)
        
        for i in range(self.Unet_depth - 1):
            for j in range(self.Unet_depth - 1 - i):
                S = np.zeros([np.max(segs[i + 1]) + 1, np.max(segs[i + j + 2]) + 1], dtype=np.float32)
                l1, l2 = np.reshape(segs[i + 1], [-1]), np.reshape(segs[i + j + 2], [-1])
                coords = np.stack([l1, l2])
                coords = np.unique(coords, axis=1)
                S[coords[0], coords[1]] = 1
                H_list_full.append(S)
        
        return segs, A_list, H_list_full

def sampling_fixed(proportion_train, proportion_val, groundtruth, random_seed=3407):
    np.random.seed(random_seed)
    classnum = int(max(groundtruth))
    train_gt = np.zeros_like(groundtruth)
    val_gt = np.zeros_like(groundtruth)
    test_gt = np.zeros_like(groundtruth)
    
    for i in range(classnum):
        indexes = [j for j, x in enumerate(groundtruth.ravel().tolist()) if x == i + 1]
        np.random.shuffle(indexes)
        
        if proportion_train < 1:
            n_train = max(int(proportion_train * len(indexes)), 2)
            n_val = max(int(proportion_val * len(indexes)), 2)
        else:
            limit = len(indexes)
            n_train = int(min(proportion_train, limit * 0.5))
            n_val = int(min(proportion_val, limit * 0.3))
            n_train = max(n_train, 2)
            n_val = max(n_val, 2)
        
        if n_train + n_val >= len(indexes):
            n_train = max(len(indexes) // 3, 1)
            n_val = max(len(indexes) // 3, 1)
        
        train_idx = indexes[:n_train]
        val_idx = indexes[n_train:n_train + n_val]
        test_idx = indexes[n_train + n_val:]
        
        train_gt[train_idx] = groundtruth[train_idx]
        val_gt[val_idx] = groundtruth[val_idx]
        test_gt[test_idx] = groundtruth[test_idx]

    return train_gt, val_gt, test_gt

def get_label_mask(line, sample, class_num, samples):
    mask = np.zeros((line * sample,), dtype=np.bool_)
    mask[samples != 0] = True
    return mask

class ClassBalancedFocalLoss(nn.Module):
    # [Improvement] Added label_smoothing
    def __init__(self, num_classes: int, gamma: float = 2.0, alpha=None, label_smoothing=0.0):
        super().__init__()
        self.gamma = gamma
        self.label_smoothing = label_smoothing
        self.register_buffer("alpha", alpha)
        self.num_classes = num_classes
    
    @staticmethod
    def from_labels(num_classes: int, labels: np.ndarray, gamma: float = 2.0, label_smoothing=0.0, device=None):
        counts = np.zeros((num_classes,), dtype=np.float64)
        for c in range(1, num_classes + 1):
            counts[c - 1] = np.sum(labels == c)
        inv = 1.0 / np.maximum(counts, 1.0)
        alpha = inv / inv.mean()
        return ClassBalancedFocalLoss(
            num_classes=num_classes,
            gamma=gamma,
            alpha=torch.tensor(alpha, dtype=torch.float32, device=device),
            label_smoothing=label_smoothing
        )
    
    def forward(self, logits, targets, mask):
        if mask.sum() == 0:
            return logits.sum() * 0.0
        logits_m, targets_m = logits[mask], targets[mask]
        
        # Log Softmax
        logp = F.log_softmax(logits_m, dim=-1)
        p = torch.exp(logp)
        
        # Focal Weights
        logpt = logp.gather(1, targets_m.view(-1, 1)).squeeze(1)
        pt = p.gather(1, targets_m.view(-1, 1)).squeeze(1)
        alpha_t = self.alpha.gather(0, targets_m)
        focal_weight = -alpha_t * (1.0 - pt).pow(self.gamma)
        
        # Label Smoothing Implementation
        if self.label_smoothing > 0:
            # Smooth targets: (1-e) for true class, e/(K-1) for others
            loss = 0
            n_classes = logits_m.size(-1)
            # Correct class part
            loss += focal_weight * logpt * (1.0 - self.label_smoothing)
            # Smoothing part (weighted by alpha and focal term approx or uniform)
            # Simplified smoothing integration with Focal Loss:
            # We apply smoothing to the target distribution.
            # However, standard Focal Loss doesn't trivially combine with smoothing.
            # Here we use a weighted Cross Entropy style smoothing where weights come from Focal.
            
            # Alternative: Just smooth the log probs and apply focal weight scalar
            smooth_loss = -logp.mean(dim=-1) # Uniform distribution part
            # Combine: (1-eps) * Focal + eps * Weighted_Uniform
            # Note: Strict mathematical focal label smoothing is complex. 
            # We use a robust approximation: Soften the 'logpt' in the focal term.
            
            loss = focal_weight * ((1 - self.label_smoothing) * logpt + self.label_smoothing * logp.mean(dim=-1))
            return loss.mean()
        else:
            loss = focal_weight * logpt
            return loss.mean()

# ==============================================================================
# Model Modules
# ==============================================================================
class AdvancedPixelScanMamba(nn.Module):
    def __init__(self, d_model, d_state=16, expand=2):
        super().__init__()
        self.directions = nn.ModuleList([
            Mamba(d_model=d_model, d_state=d_state, expand=expand)
            for _ in range(4)
        ])
        self.norm = RMSNorm(d_model)
        self.attn_fc = nn.Sequential(
            nn.Linear(d_model, d_model // 4),
            nn.ReLU(),
            nn.Linear(d_model // 4, 4),
            nn.Softmax(dim=-1)
        )
    
    def forward(self, x_hw_c):
        H, W, C = x_hw_c.shape
        L = H * W
        
        x1 = x_hw_c.reshape(1, L, C)
        y1 = self.directions[0](x1)
        
        x2 = x_hw_c.permute(1, 0, 2).reshape(1, L, C)
        y2 = self.directions[1](x2).reshape(W, H, C).permute(1, 0, 2).reshape(1, L, C)
        
        x3_img = torch.rot90(x_hw_c, 1, [0, 1])
        x3 = x3_img.reshape(1, L, C)
        y3 = self.directions[2](x3).reshape(W, H, C)
        y3 = torch.rot90(y3, -1, [0, 1]).reshape(1, L, C)
        
        x4_img = torch.flip(x_hw_c, [1])
        x4 = x4_img.reshape(1, L, C)
        y4 = self.directions[3](x4).reshape(H, W, C)
        y4 = torch.flip(y4, [1]).reshape(1, L, C)
        
        stacked = torch.cat([y1, y2, y3, y4], dim=0)
        weights = self.attn_fc(stacked.mean(dim=1).mean(dim=0, keepdim=True))
        out = (stacked * weights.view(4, 1, 1)).sum(dim=0)
        
        return self.norm(out.squeeze(0))

class DynamicGeneAggregation(nn.Module):
    def __init__(self, num_branches, channels):
        super().__init__()
        self.project = nn.Sequential(
            nn.Linear(channels, channels // 4),
            nn.ReLU(),
            nn.Linear(channels // 4, num_branches),
            nn.Softmax(dim=-1)
        )
    
    def forward(self, feature_list):
        stack = torch.stack(feature_list, dim=0)
        global_ctx = stack.mean(dim=1).mean(dim=0)
        weights = self.project(global_ctx)
        return (stack * weights.view(-1, 1, 1)).sum(dim=0)

class MambaChannelAttention(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.mamba = Mamba(d_model=channels, d_state=8, expand=1)
        self.norm = RMSNorm(channels)
    
    def forward(self, x_nc):
        v = x_nc.mean(dim=0, keepdim=True)
        s = self.norm(v).unsqueeze(1)
        a = torch.sigmoid(self.mamba(s).squeeze(1))
        return x_nc * a

class ChebnetII_prop(MessagePassing):
    def __init__(self, K: int, **kwargs):
        super().__init__(aggr="add", **kwargs)
        self.K = K
        self.temp = nn.Parameter(torch.ones(self.K + 1))
    
    def forward(self, x, edge_index, edge_weight=None):
        num_nodes = x.size(0)
        coe = F.relu(self.temp).clone()
        edge_index_norm, norm = get_laplacian(
            edge_index, edge_weight, normalization="sym", dtype=x.dtype, num_nodes=num_nodes
        )
        edge_index_tilde, norm_tilde = add_self_loops(
            edge_index_norm, norm, fill_value=-1.0, num_nodes=num_nodes
        )
        Tx_0 = x
        Tx_1 = self.propagate(edge_index_tilde, x=x, norm=norm_tilde)
        out = coe[0] / 2 * Tx_0 + coe[1] * Tx_1
        for k in range(2, self.K + 1):
            Tx_2 = self.propagate(edge_index_tilde, x=Tx_1, norm=norm_tilde)
            Tx_2 = 2 * Tx_2 - Tx_0
            out = out + coe[k] * Tx_2
            Tx_0, Tx_1 = Tx_1, Tx_2
        return out
    
    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j

class ChebyshevGCNLayer(nn.Module):
    def __init__(self, input_dim, output_dim, adjacency_matrix, k_order=2, dropout=0.1):
        super().__init__()
        self.input_norm = nn.BatchNorm1d(input_dim)
        self.project = nn.Linear(input_dim, output_dim)
        self.output_norm = nn.BatchNorm1d(output_dim)
        self.activation = nn.LeakyReLU(inplace=True)
        self.dropout = nn.Dropout(dropout)
        self.cheb_prop = ChebnetII_prop(K=k_order)
        
        edge_index, edge_weight = dense_to_sparse(adjacency_matrix)
        self.register_buffer("edge_index", edge_index.long())
        self.register_buffer("edge_weight", edge_weight)
    
    def forward(self, H):
        H = self.input_norm(H)
        H = self.project(H)
        out = self.cheb_prop(H, self.edge_index, self.edge_weight)
        out = self.output_norm(out)
        out = self.activation(out)
        return self.dropout(out)

class SSConv(nn.Module):
    def __init__(self, in_ch, out_ch, kernel_size=5):
        super().__init__()
        self.conv = nn.Sequential(
            nn.BatchNorm2d(in_ch),
            nn.Conv2d(in_ch, out_ch, 1),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, kernel_size, padding=kernel_size // 2, groups=out_ch),
            nn.LeakyReLU(inplace=True)
        )
    def forward(self, x):
        return self.conv(x)

class GCNASnet_Final(nn.Module):
    def __init__(self, args, hierarchy_matrices, adjacency_matrices):
        super().__init__()
        self.channel = args.bands
        self.class_num = args.class_num
        self.H_list = hierarchy_matrices
        self.A_list = adjacency_matrices
        self.layer_count = args.Unet_depth
        
        dropout_rate = getattr(args, 'dropout', 0.1)

        self.H_list_Hat_T = [
            (temp / (torch.sum(temp, 0, keepdim=True) + 1e-6)).t()
            for temp in hierarchy_matrices
        ]
        
        # [Improvement] Increased base channels from 8 to 16
        layer_channels = 16 
        Layers = [layer_channels]
        for _ in range(self.layer_count):
            layer_channels *= 2
            Layers.append(layer_channels)

        self.CNN_head_layer = SSConv(self.channel, Layers[-1], kernel_size=5)
        self.pixel_cross = AdvancedPixelScanMamba(d_model=Layers[-1])
        self.chan_attn = MambaChannelAttention(channels=Layers[-1])

        self.En_GCN_layers0 = nn.ModuleList([
            ChebyshevGCNLayer(Layers[-i - 1], Layers[-i - 2], self.A_list[i], dropout=dropout_rate)
            for i in range(self.layer_count - 1)
        ])
        self.En_GCN_layers1 = nn.ModuleList([
            ChebyshevGCNLayer(Layers[-i - 2], Layers[0], self.A_list[-1], dropout=dropout_rate)
            for i in range(self.layer_count - 1)
        ])
        self.gene_en_agg = DynamicGeneAggregation(len(self.En_GCN_layers1), Layers[0])

        self.bottleneck_dim = Layers[0]
        self.bottleneck_mamba = Mamba(d_model=self.bottleneck_dim, d_state=16)
        self.bottleneck_norm = RMSNorm(self.bottleneck_dim)

        self.De_GCN_layers0 = nn.ModuleList([
            ChebyshevGCNLayer(Layers[i] + Layers[i + 1], Layers[i + 1], self.A_list[-i - 2], dropout=dropout_rate)
            for i in range(self.layer_count - 2)
        ])
        self.De_GCN_layers1 = nn.ModuleList([
            ChebyshevGCNLayer(Layers[i] + Layers[-2], Layers[-2], self.A_list[0], dropout=dropout_rate)
            for i in range(self.layer_count - 1)
        ])
        self.gene_de_agg = DynamicGeneAggregation(len(self.De_GCN_layers1), Layers[-2])

        self.CNN_tail_layer = SSConv(Layers[-1] + Layers[-2], Layers[-1], kernel_size=5)
        self.classifier = nn.Linear(Layers[-1], self.class_num)
        self.aux_classifier = nn.Linear(Layers[-1], self.class_num)

    def forward(self, x_hwc):
        (h, w, c) = x_hwc.shape
        encoder_features0 = []
        encoder_features1 = []
        decoder_features0 = []
        decoder_features1 = []

        x_i = torch.unsqueeze(x_hwc.permute([2, 0, 1]), 0)
        H_0 = self.CNN_head_layer(x_i)
        H_0 = torch.squeeze(H_0, 0).permute([1, 2, 0]).contiguous()
        
        H_0_flat = self.pixel_cross(H_0)
        H_0_flat = self.chan_attn(H_0_flat)
        logits_aux = self.aux_classifier(H_0_flat)

        H_i = torch.mm(self.H_list_Hat_T[0], H_0_flat)
        H_i = self.En_GCN_layers0[0](H_i)
        encoder_features0.append(H_i)

        t = 1
        for i in range(len(self.En_GCN_layers0) - 1):
            H_i = torch.mm(self.H_list_Hat_T[t], H_i)
            t += len(self.En_GCN_layers0) - i
            H_i = self.En_GCN_layers0[i + 1](H_i)
            encoder_features0.append(H_i)

        t = len(self.En_GCN_layers1)
        for i in range(len(self.En_GCN_layers1)):
            H_i = torch.mm(self.H_list_Hat_T[t], encoder_features0[i])
            t += len(self.En_GCN_layers1) - 1 - i
            H_i = self.En_GCN_layers1[i](H_i)
            encoder_features1.append(H_i)

        final_encoder_feature = self.gene_en_agg(encoder_features1)
        
        bn_input = final_encoder_feature.unsqueeze(0)
        bn_out = self.bottleneck_mamba(bn_input)
        final_encoder_feature = final_encoder_feature + self.bottleneck_norm(bn_out).squeeze(0)
        H_i = final_encoder_feature
        decoder_features0.append(H_i)

        t = 1
        for i in range(len(self.De_GCN_layers0)):
            H_i = torch.mm(self.H_list[-t], H_i)
            t += i + 2
            H_i = torch.cat([H_i, encoder_features0[-i - 1]], dim=-1)
            H_i = self.De_GCN_layers0[i](H_i)
            decoder_features0.append(H_i)

        for i in range(len(self.De_GCN_layers1)):
            t = len(self.De_GCN_layers1) - i
            H_i = torch.mm(self.H_list[t], decoder_features0[i])
            H_i = torch.cat([H_i, encoder_features0[0]], dim=-1)
            H_i = self.De_GCN_layers1[i](H_i)
            decoder_features1.append(H_i)

        final_decoder_feature = self.gene_de_agg(decoder_features1)
        H_i = torch.mm(self.H_list[0], final_decoder_feature)
        H_i = torch.cat([H_i, H_0_flat], dim=-1)
        
        final = self.CNN_tail_layer(H_i.reshape([1, h, w, -1]).permute([0, 3, 1, 2]))
        final = final.squeeze(0).permute(1, 2, 0).reshape(h * w, -1)
        logits_main = self.classifier(final)
        return logits_main, logits_aux

def apply_tta(model, net_input, line, sample, class_num):
    model.eval()
    logits_list = []
    with torch.no_grad():
        logits_1, _ = model(net_input)
        logits_list.append(logits_1)
        
        input_flip_h = torch.flip(net_input, dims=[1])
        logits_flip_h, _ = model(input_flip_h)
        logits_flip_h = logits_flip_h.view(line, sample, -1)
        logits_flip_h = torch.flip(logits_flip_h, dims=[1]).reshape(line * sample, -1)
        logits_list.append(logits_flip_h)
        
        input_flip_v = torch.flip(net_input, dims=[0])
        logits_flip_v, _ = model(input_flip_v)
        logits_flip_v = logits_flip_v.view(line, sample, -1)
        logits_flip_v = torch.flip(logits_flip_v, dims=[0]).reshape(line * sample, -1)
        logits_list.append(logits_flip_v)
        
        logits_final = torch.stack(logits_list, dim=0).mean(dim=0)
    return logits_final

def calculate_metrics(pred, truth, class_num):
    OA = accuracy_score(truth, pred)
    confusion = confusion_matrix(truth, pred)
    per_class_acc = np.diag(confusion) / np.sum(confusion, axis=1)
    AA = np.mean(per_class_acc)
    Kappa = cohen_kappa_score(truth, pred)
    cls_report = classification_report(
        truth, pred, labels=list(range(1, class_num + 1)), digits=4, zero_division=0,
    )
    return {
        'OA': OA, 'AA': AA, 'Kappa': Kappa,
        'per_class_acc': per_class_acc,
        'confusion_matrix': confusion,
        'classification_report': cls_report
    }

def plot_results(pred, data_gt, class_num, output_dir, run_id, OA):
    ksc_color = np.array([
        [0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0],
        [255, 0, 255], [0, 255, 255], [200, 100, 0], [0, 200, 100],
        [100, 0, 200], [200, 0, 100], [100, 200, 0], [0, 100, 200],
        [150, 75, 75], [75, 150, 75], [75, 75, 150], [255, 100, 100]
    ], dtype=np.float32) / 255.0
    cmap = matplotlib.colors.ListedColormap(ksc_color[: class_num + 1])
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    axes[0].imshow(pred, interpolation="none", cmap=cmap, vmin=0, vmax=class_num)
    axes[0].set_title(f"Prediction (OA={OA:.4f})")
    axes[0].axis("off")
    axes[1].imshow(data_gt, interpolation="none", cmap=cmap, vmin=0, vmax=class_num)
    axes[1].set_title("Ground Truth")
    axes[1].axis("off")
    fig.tight_layout()
    fig.savefig(os.path.join(output_dir, "result.png"), dpi=200)
    fig.savefig(os.path.join(output_dir, f"result_{run_id}.png"), dpi=200)
    plt.close(fig)

def add_input_noise(x, noise_level=0.01):
    if not isinstance(x, torch.Tensor):
        return x
    noise = torch.randn_like(x) * noise_level
    return x + noise

# ==============================================================================
# Main
# ==============================================================================
def main():
    parser = argparse.ArgumentParser(description="GCN-Mamba for Hyperspectral Image Classification")
    parser.add_argument("--dataset", type=str, default="PU", choices=["IP", "PU", "SA"])
    parser.add_argument("--dataset_dir", type=str, default="/data/wk002/LGY/LSY/data/")
    parser.add_argument("--train", type=int, default=30)
    parser.add_argument("--val", type=int, default=10)
    parser.add_argument("--Unet_depth", type=int, default=3) 
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--finetune_epochs", default=300, type=int)
    parser.add_argument("--output_dir", type=str, default="./output/final_report/")
    parser.add_argument("--amp", action="store_true")
    parser.add_argument("--seed", type=int, default=3407)
    parser.add_argument("--patience", type=int, default=60)
    parser.add_argument("--use_tta", action="store_true", default=False) 
    parser.add_argument("--pca_components", type=int, default=30)
    parser.add_argument("--dropout", type=float, default=0.1) 
    
    # [Improvement] Added label_smoothing argument
    parser.add_argument("--label_smoothing", type=float, default=0.1)
    
    args = parser.parse_args()

    seed_everything(args.seed)
    args.output_dir = os.path.abspath(args.output_dir)
    os.makedirs(args.output_dir, exist_ok=True)
    logger, run_id = setup_logger(args.output_dir)
    tracker = TimeTracker()
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    
    logger.info(f"Using device: {device}")
    logger.info(f"Random seed: {args.seed}")
    logger.info(f"Arguments: {vars(args)}")

    # Data Loading
    if args.dataset == "IP":
        data_hsi = sio.loadmat(os.path.join(args.dataset_dir, "indian/Indian_pines_corrected.mat"))["indian_pines_corrected"]
        data_gt = sio.loadmat(os.path.join(args.dataset_dir, "indian/Indian_pines_gt.mat"))["indian_pines_gt"]
    elif args.dataset == "PU": 
        data_hsi = sio.loadmat(os.path.join(args.dataset_dir, "PaviaU/PaviaU.mat"))["paviaU"]
        data_gt = sio.loadmat(os.path.join(args.dataset_dir, "PaviaU/PaviaU_gt.mat"))["paviaU_gt"]
    elif args.dataset == "SA": 
        data_hsi = sio.loadmat(os.path.join(args.dataset_dir, "Salinas/Salinas_corrected.mat"))["salinas_corrected"]
        data_gt = sio.loadmat(os.path.join(args.dataset_dir, "Salinas/Salinas_gt.mat"))["salinas_gt"]
    
    line, sample, band = data_hsi.shape
    class_num = int(np.max(data_gt))
    gt = data_gt.reshape(line * sample,)
    
    # PCA
    bands = args.pca_components
    Xpca = data_hsi.reshape(-1, band)
    Xpca = PCA(n_components=bands, whiten=False).fit_transform(Xpca)
    Xpca = Xpca.reshape(line, sample, bands)
    
    # [Improvement] Advanced Sinusoidal Spatial Encoding
    x_coords = np.linspace(-np.pi, np.pi, sample)
    y_coords = np.linspace(-np.pi, np.pi, line)
    xx, yy = np.meshgrid(x_coords, y_coords)
    # 4 channels: sin(x), cos(x), sin(y), cos(y)
    pos_enc = np.stack([np.sin(xx), np.cos(xx), np.sin(yy), np.cos(yy)], axis=-1) 
    Xpca = np.concatenate([Xpca, pos_enc], axis=-1)
    
    args.bands = bands + 4
    args.class_num = class_num

    # SLIC
    tracker.start("segment")
    logger.info("Generating hierarchical superpixel segmentation...")
    SM = SegmentMap(Xpca, args.Unet_depth, random_seed=args.seed)
    segments, A_list, H_list = SM.getHierarchy()
    A_list_gpu = [torch.from_numpy(np.array(A, dtype=np.float32)).to(device) for A in A_list]
    H_list_gpu = [torch.from_numpy(np.array(H, dtype=np.float32)).to(device) for H in H_list]
    tracker.stop("segment")
    logger.info(f"Segmentation completed in {tracker.get_duration('segment'):.2f}s")

    # Splitting
    train_gt, val_gt, test_gt = sampling_fixed(args.train, args.val, gt, random_seed=args.seed)
    train_mask = get_label_mask(line, sample, class_num, train_gt)
    val_mask = get_label_mask(line, sample, class_num, val_gt)
    test_mask = get_label_mask(line, sample, class_num, test_gt)
    
    train_samples = np.sum(train_mask)
    val_samples = np.sum(val_mask)
    test_samples = np.sum(test_mask)

    train_gt_t = torch.from_numpy(train_gt.astype(np.int64)).to(device)
    val_gt_t = torch.from_numpy(val_gt.astype(np.int64)).to(device)
    test_gt_t = torch.from_numpy(test_gt.astype(np.int64)).to(device)
    train_mask_t = torch.from_numpy(train_mask).to(device)
    val_mask_t = torch.from_numpy(val_mask).to(device)
    test_mask_t = torch.from_numpy(test_mask).to(device)
    net_input = torch.from_numpy(Xpca.astype(np.float32)).to(device)

    # Model Init
    model = GCNASnet_Final(args, H_list_gpu, A_list_gpu).to(device)
    num_params = count_parameters(model)
    logger.info(f"Total trainable parameters: {num_params:,} ({num_params / 1e6:.4f}M)")
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-2)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.finetune_epochs, eta_min=1e-6)
    scaler = amp.GradScaler(enabled=args.amp)
    
    # [Improvement] Pass label_smoothing to Loss
    focal = ClassBalancedFocalLoss.from_labels(
        class_num, train_gt, gamma=3.0, label_smoothing=args.label_smoothing, device=device
    )
    early_stopping = EarlyStopping(patience=args.patience, mode='max')
    
    save_config(args, args.output_dir, run_id, num_params, {
        'train_samples': int(train_samples),
        'val_samples': int(val_samples),
        'test_samples': int(test_samples),
        'image_shape': [line, sample, args.bands]
    })

    # Training
    logger.info("Starting training with Sinusoidal Positional Encoding & Increased Width...")
    tracker.start("train")
    best_val_oa = 0.0
    train_losses = []
    val_oas = []
    
    for epoch in range(args.finetune_epochs):
        model.train()
        aux_w = 0.1 + 0.5 * (1 + math.cos(math.pi * epoch / args.finetune_epochs)) / 2
        optimizer.zero_grad()
        
        with amp.autocast(enabled=args.amp):
            # Input Noise
            noisy_input = add_input_noise(net_input, noise_level=0.01) if epoch < args.finetune_epochs * 0.8 else net_input
            
            logits_main, logits_aux = model(noisy_input)
            targets = train_gt_t.long() - 1
            loss_m = focal(logits_main, targets, train_mask_t)
            loss_a = focal(logits_aux, targets, train_mask_t)
            loss = loss_m + aux_w * loss_a
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        train_losses.append(loss.item())

        model.eval()
        with torch.no_grad():
            logits_v, _ = model(net_input)
            pred = torch.argmax(logits_v, dim=-1)
            correct = (pred[val_mask_t] == (val_gt_t[val_mask_t] - 1)).float().mean()
            val_oa = correct.item()
        val_oas.append(val_oa)
        
        should_save = early_stopping(val_oa, epoch)
        if should_save: 
            best_val_oa = val_oa
            torch.save(model.state_dict(), os.path.join(args.output_dir, "best_model.pt"))
        
        scheduler.step()
        
        if (epoch + 1) % 10 == 0:
            logger.info(f"Epoch {epoch + 1}: Loss={loss.item():.4f}, ValOA={val_oa:.4f}, BestOA={best_val_oa:.4f}")
        
        if early_stopping.early_stop:
            logger.info(f"Early stopping at epoch {epoch + 1}")
            break
    
    tracker.stop("train")
    
    # Testing
    logger.info("Loading best model...")
    tracker.start("test")
    model.load_state_dict(torch.load(os.path.join(args.output_dir, "best_model.pt")))
    model.eval()
    
    if args.use_tta:
        logits_final = apply_tta(model, net_input, line, sample, class_num)
    else:
        with torch.no_grad():
            logits_final, _ = model(net_input)
    tracker.stop("test")
    
    pred = torch.argmax(logits_final, dim=-1).cpu().numpy() + 1
    pred = pred.reshape(line, sample)
    pred[data_gt == 0] = 0
    pred_flat = pred.reshape(-1)
    res = pred_flat[test_mask]
    truth = gt[test_mask]
    
    metrics = calculate_metrics(res, truth, class_num)
    plot_results(pred, data_gt, class_num, args.output_dir, run_id, metrics['OA'])

    logger.info(f"Overall Accuracy: {metrics['OA'] * 100:.2f}%")
    logger.info("\n" + metrics['classification_report'])
    
    results = {
        'OA': float(metrics['OA']),
        'AA': float(metrics['AA']),
        'Kappa': float(metrics['Kappa']),
        'per_class_acc': metrics['per_class_acc'].tolist(),
    }
    with open(os.path.join(args.output_dir, f"results_{run_id}.json"), 'w') as f:
        json.dump(results, f, indent=2)
  
    # ===========================================================================
    # 最终报告
    # ===========================================================================
    logger.info("\n")
    logger.info("=" * 60)
    logger.info(f"           EXPERIMENT RESULTS ({args.dataset})            ")
    logger.info("=" * 60)
    logger.info(f"{'Metric':<20} | {'Value':<15}")
    logger.info("-" * 40)
    logger.info(f"{'Overall Accuracy':<20} | {metrics['OA'] * 100:.2f}%")
    logger.info(f"{'Average Accuracy':<20} | {metrics['AA'] * 100:.2f}%")
    logger.info(f"{'Kappa Coefficient':<20} | {metrics['Kappa'] * 100:.2f}")
    logger.info("-" * 40)
    logger.info(f"{'Train Time':<20} | {tracker.get_duration('train'):.4f} s")
    logger.info(f"{'Test Time':<20} | {tracker.get_duration('test'):.4f} s")
    logger.info(f"{'Segment Time':<20} | {tracker.get_duration('segment'):.4f} s")
    logger.info("-" * 40)
    logger.info(f"{'Total Params':<20} | {num_params / 1e6:.4f} M")
    logger.info(f"{'Train Samples':<20} | {train_samples}")
    logger.info(f"{'Val Samples':<20} | {val_samples}")
    logger.info(f"{'Test Samples':<20} | {test_samples}")
    logger.info(f"{'Best Val Epoch':<20} | {int(np.argmax(val_oas)) + 1 if val_oas else 0}")
    logger.info(f"{'TTA Enabled':<20} | {args.use_tta}")
    logger.info("=" * 60)

    logger.info("\nClassification Report (precision/recall/f1/support):")
    logger.info("\n" + metrics['classification_report'])
    
    logger.info("\nPer-Class Accuracy:")
    for i, acc in enumerate(metrics['per_class_acc']):
        logger.info(f"  Class {i + 1:02d}: {acc * 100:.2f}%")
    logger.info("=" * 60)
    
    # 保存训练曲线
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    axes[0].plot(train_losses)
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Training Loss')
    axes[0].grid(True)
    
    axes[1].plot(val_oas)
    axes[1].axhline(y=best_val_oa, color='r', linestyle='--', label=f'Best: {best_val_oa:.4f}')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Validation OA')
    axes[1].set_title('Validation Accuracy')
    axes[1].legend()
    axes[1].grid(True)
    
    fig.tight_layout()
    fig.savefig(os.path.join(args.output_dir, f"training_curve_{run_id}.png"), dpi=250)
    plt.close(fig)
    
    # 保存最终结果
    results = {
        'OA': float(metrics['OA']),
        'AA': float(metrics['AA']),
        'Kappa': float(metrics['Kappa']),
        'per_class_acc': metrics['per_class_acc'].tolist(),
        'train_time': tracker.get_duration('train'),
        'test_time': tracker.get_duration('test'),
        'segment_time': tracker.get_duration('segment'),
        'num_params': num_params,
        'best_epoch': int(np.argmax(val_oas)) + 1 if val_oas else 0,
        'total_epochs': len(train_losses)
    }
    
    with open(os.path.join(args.output_dir, f"results_{run_id}.json"), 'w') as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"\nResults saved to: {args.output_dir}")
    logger.info("Experiment completed successfully!")
    
    return results

if __name__ == "__main__":
    main()
